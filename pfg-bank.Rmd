---
title: "PFG-bank: Data Driven Credit Card Design"
output: html_document
---

* Team-lead gitlab id:
* Group number:
* Group name:
* Team member names:

```{r r_setup, include = FALSE}
## initial settings
knitr::opts_chunk$set(
  comment = NA,
  echo = TRUE,
  error = TRUE,
  cache = FALSE,
  message = FALSE,
  dpi = 96,
  warning = FALSE
)

## width to use when printing tables etc.
options(
  width = 250,
  scipen = 100,
  max.print = 5000,
  stringsAsFactors = FALSE
)
```

<style>
.table {
  width: auto;
}
ul, ol {
  padding-left: 18px;
}
pre, code, pre code {
  overflow: auto;
  white-space: pre;
  word-wrap: normal;
  background-color: #ffffff;
}
</style>

## Setup

Please complete this R-markdown document by answering the questions in `pfg-bank.pdf` on Dropbox (week10/readings/). The code block below will load the historical data from exhibits 1 and 2. Please DO NOT change the code used to load the data. Create an HTML (Notebook) file with all your results and comments and push both the Rmarkdown and HTML file to GitLab when you are done. All analysis results MUST be reproducible (i.e., the TA and I must be able to recreate the HTML from the R-markdown file without changes or errors).

```{r}
fp <- radiant.data::find_dropbox()
exhibit1 <- readxl::read_excel(file.path(fp, "MGTA455-2019/data/exhibits.xlsx"), sheet = "exhibit1")
exhibit2 <- readxl::read_excel(file.path(fp, "MGTA455-2019/data/exhibits.xlsx"), sheet = "exhibit2")
```

## Question answers

### Question 1

```{r include = FALSE}
library(dplyr)
library(tidyverse)
library(radiant)
library(ggplot2)
library(data.table)
library(stringr)
```

As we can see in exhibit2, the expected LTVs vary with BK score groups. The higher the BK score, the lower the lifetime customer value. It makes sense as the probability of defaulting rises with bankcruptcy score and we adjust downwards our expected repayments.

```{r}
exhibit2 %>% 
  select(ltv150, ltv200, ltv250) %>%
  colMeans()

```

In addition, within each BK group, we can see LTV varies with product features. 

1. LTV increases with APR. With higher interest rate charges, PFG has higher expected revenues, hence higher projected LTV;

```{r}
# ARP
exhibit2 %>% 
  group_by(apr) %>% 
  summarise(avg_bk150 = mean(ltv150),
            avg_bk200 = mean(ltv200),
            avg_bk250 = mean(ltv250))
```

2. LTV will also rise if banks issue variable rate credit cars, because banks have the channels to pass along rising borrowing costs to customers, hence protecting their margins. 

```{r}
# Fixed vs Var

exhibit2 %>% 
  group_by(fixed_var) %>% 
  summarise(avg_bk150 = mean(ltv150),
            avg_bk200 = mean(ltv200),
            avg_bk250 = mean(ltv250))
```

3. Higher annual fee also means higher projected LTV, as the fixed annual fee of $20 is guranteed revenues for banks.


```{r}
# Annual Fee

exhibit2 %>% 
  group_by(annual_fee) %>% 
  summarise(avg_bk150 = mean(ltv150),
            avg_bk200 = mean(ltv200),
            avg_bk250 = mean(ltv250))
```


### Question 2

In this question, we separated exhibit1 dataset by three banktcruptcy score groups and expanded datasets to the length of mailing counts. Then we ran logistic regressions using actual response as predicted variable, and APR rate, fixed/variable rate and annual fee. Below are the predictive results. 

```{r}
# expand data frame

exhibit1_150 <- exhibit1 %>%
  filter(bk_score == 150) %>% 
  select(apr, fixed_var, annual_fee, non_resp, resp) %>% 
  gather(key = 'result', value = 'count', -c(apr, fixed_var, annual_fee)) %>% 
  slice(rep(1:n(), count)) %>% 
  select(-count)


exhibit1_200 <- exhibit1 %>%
  filter(bk_score == 200) %>% 
  select(apr, fixed_var, annual_fee, non_resp, resp) %>% 
  gather(key = 'result', value = 'count', -c(apr, fixed_var, annual_fee)) %>% 
  slice(rep(1:n(), count)) %>% 
  select(-count)

exhibit1_250 <- exhibit1 %>%
  filter(bk_score == 250) %>% 
  select(apr, fixed_var, annual_fee, non_resp, resp) %>% 
  gather(key = 'result', value = 'count', -c(apr, fixed_var, annual_fee)) %>% 
  slice(rep(1:n(), count)) %>% 
  select(-count)


exhibit1_150 <- exhibit1_150 %>% mutate_all(as.factor)
exhibit1_200 <- exhibit1_200 %>% mutate_all(as.factor)
exhibit1_250 <- exhibit1_250 %>% mutate_all(as.factor)

```


**BK150 Group**

```{r fig.width = 7, fig.height = 4.09, dpi = 144}
result150 <- logistic(
  exhibit1_150, 
  rvar = "result", 
  evar = c("apr", "fixed_var", "annual_fee"), 
  lev = "resp"
)
summary(result150)
plot(result150, plots = "coef", custom = FALSE)
```

**BK200 Group**

```{r fig.width = 7, fig.height = 3.88, dpi = 144}
result200 <- logistic(
  exhibit1_200, 
  rvar = "result", 
  evar = c("apr", "annual_fee"), 
  lev = "resp"
)
summary(result200)
plot(result200, plots = "coef", custom = FALSE)
```


**BK250 Group**

```{r fig.width = 7, fig.height = 4.31, dpi = 144}
result250 <- logistic(
  exhibit1_250, 
  rvar = "result", 
  evar = c("apr", "fixed_var", "annual_fee"), 
  lev = "resp"
)
summary(result250)
plot(result250, plots = "coef", custom = FALSE)
```

Generally, we don't find the predictive models useful in picking up product features' effects on response rate 

across BK groups and here are the reasons. 

* 1. The product feature combinations aren't comprehensive in BK150 and BK200, which makes it difficult to compare the effects of one feature while holding other features the same. To be specific, In group BK150, we don't have instance of APR 19.8; while in group BK200, we don't have APR 16.8 or fixed/variable rate.

* 2. External factors have settled in since the launch of previous mailings, in terms of competitors' offers and prevailing borrowing costs. Both would affect how customers would react to PFG's product combinations. 

However, the historical data did affirm our assumptions on how variations in these variables would affect customers' response rate. For example, in group BK250, the odds ratio of annual_fee|20 is 0.284, meaning that if PFG charges $20 for annual fee, the odds of a customer opening an account will decrease by 71.6%, holding all else constant. Also, given the only variables we have, we see that different BK groups react to the same product differently. 

In our testing strategy, we used the average response rate of each product combinations, regardless of BK group, and check the ranking of average response rate. We used this relative ranking as reference in determining sample size. More details will be discussed in Question 4. 


```{r}
# compare product feature effect across different BK groups

coeffs <- c("apr|16.8", "apr|19.8", "fixed_var|Variable", "annual_fee|20")

# 250, 200, 150
apr_168 <- c(result250[["coeff"]][["OR"]][2], 0, result150[["coeff"]][["OR"]][2])
apr_198 <- c(result250[["coeff"]][["OR"]][3], result200[["coeff"]][["OR"]][2],0)
var_to_fixed <- c(result250[["coeff"]][["OR"]][4], 0, result150[["coeff"]][["OR"]][3])
annual_fee <- c(result250[["coeff"]][["OR"]][5], result200[["coeff"]][["OR"]][3], result150[["coeff"]][["OR"]][4])

or_df <- data.frame(bkgroup = c("BK250", "BK200", "BK150"),
                    apr_168 = apr_168,
                    apr_198 = apr_198,
                    var_to_fixed = var_to_fixed,
                    annual_fee = annual_fee)

or_df %>% 
  gather(key = 'feature', value = 'odds_ratio', -bkgroup) %>% 
  ggplot(aes(x = factor(bkgroup), y=odds_ratio)) +
  geom_bar(stat = 'identity', position = "dodge", aes(fill = feature)) +
  scale_fill_brewer(palette = "Set1") + 
  labs(main = "Product Feature Effects on Response Odds Ratio", 
       x = 'BK Group')

```

### Question 3

In our predictions after round 1, it looks that all customers would prefer 

```{r message = FALSE}
# import round 1 test results

pfg_150 <- read_csv("pfg_150.csv")
pfg_200 <- read_csv("pfg_200.csv")
pfg_250 <- read_csv("pfg_250.csv")

# change type product and expand for logistic regression

pfg_150 <- mutate(pfg_150, no_resp = Sent - Responses)
pfg_200 <- mutate(pfg_200, no_resp = Sent - Responses)
pfg_250 <- mutate(pfg_250, no_resp = Sent - Responses)


pfg_150 <- gather(pfg_150, responce, freq, Responses, no_resp, factor_key = TRUE)
pfg_200 <- gather(pfg_200, responce, freq, Responses, no_resp, factor_key = TRUE)
pfg_250 <- gather(pfg_250, responce, freq, Responses, no_resp, factor_key = TRUE)

pfg_150 <- mutate_at(pfg_150, .vars = vars(apr, annual_fee), .funs = as_factor)
pfg_200 <- mutate_at(pfg_200, .vars = vars(apr, annual_fee), .funs = as_factor)
pfg_250 <- mutate_at(pfg_250, .vars = vars(apr, annual_fee), .funs = as_factor)

# input for response rate prediction

exhibit2 <- mutate_at(exhibit2, .vars = vars(apr, annual_fee), .funs = as_factor)

```


**Logistic Regression of BK150 after Round1**

```{r}
result <- logistic(
  pfg_150, 
  rvar = "responce", 
  evar = c("apr", "fixed_var", "annual_fee"), 
  lev = "Responses", 
  wts = "freq"
)
summary(result)


pred <- predict(result, pred_data = exhibit2)
print(pred)
exhibit2 <- store(exhibit2, pred, name = "pred_150")
exhibit2$pred_150_lower <- pred$`2.5%`
exhibit2$pred_150_higher <- pred$`97.5%`
```


**Logistic Regression of BK200 after Round1**

```{r}

result <- logistic(
  pfg_200, 
  rvar = "responce", 
  evar = c("apr", "fixed_var", "annual_fee"), 
  lev = "Responses", 
  wts = "freq"
)
summary(result)

pred <- predict(result, pred_data = exhibit2)
print(pred)
exhibit2 <- store(exhibit2, pred, name = "pred_200")
exhibit2$pred_200_lower <- pred$`2.5%`
exhibit2$pred_200_higher <- pred$`97.5%`
```

**Logistic Regression of BK250 after Round1**


```{r}

result <- logistic(
  pfg_250, 
  rvar = "responce", 
  evar = c("apr", "fixed_var", "annual_fee"), 
  lev = "Responses", 
  wts = "freq"
)
summary(result)

pred <- predict(result, pred_data = exhibit2)
print(pred, n = 10)
exhibit2 <- store(exhibit2, pred, name = "pred_250")
exhibit2$pred_250_lower <- pred$`2.5%`
exhibit2$pred_250_higher <- pred$`97.5%`
```

For each group of customers, we extracted the offer with highest predicted response rate. It turns out that all 3 groups prefer 14.9 ARP rate, fixed-rate APR and zero annual fees. It makes sense as customers want the products that are the most cost-effective. 

```{r}
exhibit2[which.max(exhibit2$pred_150),]
exhibit2[which.max(exhibit2$pred_200),]
exhibit2[which.max(exhibit2$pred_250),]


```

### Question 4

In our final rolling out, we chose our offer that has the highest expected CLV, which is the corresponding CLV multiplied by predicted profits. 

```{r}
# calculated expected CLV for each group 
exhibit2 <- exhibit2 %>%
  mutate(profit_150 = ltv150*pred_150,
         profit_200 = ltv200*pred_200,
         profit_250 = ltv250*pred_250)

# take a second look at upper and lower bound of expected CLV
exhibit2 <- exhibit2 %>%
  mutate(profit_150_lower = ltv150*pred_150_lower,
         profit_150_higher = ltv150*pred_150_higher,
         profit_200_lower = ltv200*pred_200_lower,
         profit_200_higher = ltv200*pred_200_higher,
         profit_250_lower = ltv250*pred_250_lower,
         profit_250_higher = ltv250*pred_250_higher)

# get offers that have the highest expected CLV
send_150 <- exhibit2 %>%
  arrange(desc(profit_150) )%>%
            slice(1) %>% 
  select(apr, fixed_var, annual_fee, pred_150)
send_150 

send_200 <- exhibit2 %>%
  arrange(desc(profit_200) )%>%
            slice(1) %>% 
  select(apr, fixed_var, annual_fee, pred_200)
send_200



send_250 <- exhibit2 %>%
  arrange(desc(profit_250) )%>%
            slice(1) %>% 
  select(apr, fixed_var, annual_fee, pred_250)

send_250


```

### Neural Network - Second Support

We also ran neural network to capture any remaining interaction effects we missed in logistic regression, if any. 

```{r}
result <- nn(
  pfg_150, 
  rvar = "responce", 
  evar = c("apr", "fixed_var", "annual_fee"), 
  lev = "Responses", 
  wts = "freq", 
  seed = 1234
)
summary(result, prn = TRUE)
pred <- predict(result, pred_data = exhibit2)
print(pred, n = 10)
exhibit2 <- store(exhibit2, pred, name = "pred_nn_150")
```



```{r}
result <- nn(
  pfg_200, 
  rvar = "responce", 
  evar = c("apr", "fixed_var", "annual_fee"), 
  lev = "Responses", 
  wts = "freq", 
  seed = 1234
)
summary(result, prn = TRUE)
pred <- predict(result, pred_data = exhibit2)
print(pred, n = 10)
exhibit2 <- store(exhibit2, pred, name = "pred_nn_200")
```





```{r}
result <- nn(
  pfg_250, 
  rvar = "responce", 
  evar = c("apr", "fixed_var", "annual_fee"), 
  lev = "Responses", 
  wts = "freq", 
  seed = 1234
)
summary(result, prn = TRUE)
pred <- predict(result, pred_data = exhibit2)
print(pred, n = 10)
exhibit2 <- store(exhibit2, pred, name = "pred_nn_250")
```


```{r}
exhibit2 <- exhibit2 %>%
  mutate(profit_nn_150 = ltv150*pred_nn_150,
         profit_nn_200 = ltv200*pred_nn_200,
         profit_nn_250 = ltv250*pred_nn_250)

```


```{r}
exhibit2[which.max(exhibit2$profit_nn_150),]
exhibit2[which.max(exhibit2$profit_nn_200),]
exhibit2[which.max(exhibit2$profit_nn_250),]

```



```{r}
exhibit2[which.max(exhibit2$pred_nn_150),]
exhibit2[which.max(exhibit2$pred_nn_200),]
exhibit2[which.max(exhibit2$pred_nn_250),]

```
Ensemble

```{r}
exhibit2 <- exhibit2 %>%
  mutate(ensemble_150  = (pred_150 +pred_nn_150) / 2,
         ensemble_200  = (pred_200 +pred_nn_200) / 2,
         ensemble_250  = (pred_250 +pred_nn_250) / 2,
         profit_ensem_150 = ensemble_150 * ltv150,
         profit_ensem_200 = ensemble_200 * ltv200,
         profit_ensem_250 = ensemble_250 * ltv250)

```



```{r}
exhibit2[which.max(exhibit2$profit_ensem_150),]
exhibit2[which.max(exhibit2$profit_ensem_200),]
exhibit2[which.max(exhibit2$profit_ensem_250),]

```












